{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fedhere/DSPS23_final/blob/main/DSPS2023_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DSPS 2023 Final Exam\n",
        "====================\n",
        "\n",
        "This exam was written by Dr. Federica Bianco and Willow Fox Fortino.\n",
        "\n",
        "***\n",
        "\n",
        "## Exam Rules\n",
        "\n",
        "**MAIN RULE: WORK ALONE!!** while for all assignments you were encouraged to work with others, for this exam you must work alone.\n",
        "\n",
        "- You may use any other resource to help you (e.g., StackOverflow, lecture slides, etc.) but you may not consult anyone who is not Dr. Bianco or Willow.\n",
        "- You are encouraged to ask questions in `#final` on Slack.\n",
        "    - Do _not_ send private messages on Slack to either Dr. Bianco or Willow, instead ask that question on `#final`. We may send you private messages in reply to your question.\n",
        "    - Do not describe in too much detail what youa are doing or share code in your questions so as to not to accidentally revealing information, we may delete your question if you do and give you directions on how to reask or instruct you to DM us.\n",
        "- You must copy this notebook to your own Google Drive _before_ you start working.\n",
        "- You have **72 hours** to work on the exam.\n",
        "\n",
        "***\n",
        "\n",
        "## How To Submit Your Exam\n",
        "- Remember to copy this notebook to your own Google Drive _before_ you start working.\n",
        "- Share this notebook with Dr. Bianco and Willow to submit.\n",
        "    - Press the 'Share' button in the top right.\n",
        "    - Make us editors when you share the notebook.\n",
        "    - Share the notebook with our emails:\n",
        "        - fbianco@udel.edu\n",
        "        - fortino@udel.edu.\n",
        "- Do _not_ push your work to GitHub. This will enable anyone to see your work. If you do this by accident, let Willow or Dr. Bianco know and we can help you remove it permanently from GitHub.\n",
        "\n",
        "***\n",
        "\n",
        "## Exam Overview\n",
        "This exam is an exercise based on the Competition for Predicting Molecular Properties (CHAMPS). Specifically, you are to predict the coupling constant between two atoms given:\n",
        "- the two atom types (e.g., C and H),\n",
        "- the coupling type (e.g., 2JHC),\n",
        "- any features you are able to create from the molecule structure (xyz) files.\n",
        "\n",
        "You can find the Kaggle page for this data [here](https://www.kaggle.com/competitions/champs-scalar-coupling/overview)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "***\n",
        "\n",
        "## Exam Expectations\n",
        "- You will be graded on the following tasks. Each task is described in more detail below.\n",
        "    1. Data Acquisition (10 points, 5 each sub-taks)\n",
        "    2. Data Cleaning, Preparation, and Fusion (this step will likely take the most effort) (20 points, 4 each sub-task)\n",
        "    3. Data Exploration (20 points overall)\n",
        "    4. Model Choice and Preprocessing (20 points, 5 each sub-task)\n",
        "    5. Model Evaluation (15 points, there are 3 subtasks but points will be awarded for the answer holistically - be detailed and insightful)\n",
        "    6. Extend Your Analysis (10 points)\n",
        "    \n",
        "    - \\+ 10 points for clean and neat presentation\n",
        "    - \\- 10 points if notebook does not run (see reproducibility below)\n",
        "- **All figures** that you submit should conform to every previously established standard for figures. Every figure should have **captions** that explain both _what_ the figure is and _why_ it is relevant. Every figure should have **axis labels**.\n",
        "- Put explanation or discussion of your work in text cells.\n",
        "- For each step of your work, justify your choices, discuss how you were successful and how your work could be improved.\n",
        "For example you might want to justify are:\n",
        "    - How do you handle missing or redundant values?\n",
        "    - Why did you choose certain hyperparameters?\n",
        "    - Why did you choose a particular model type?\n",
        "- Present your code neatly, deleting cells of code used for testing but leaving all cells needed for the code to work.\n",
        "\n",
        "***\n",
        "\n",
        "## Exam Reproducibility\n",
        "Your code must be reproducible, meaning that someone could select `Restart Kernel` and `Run All`, and they should get the _exact_ same output that you had initially.\n",
        "\n",
        "To be clear: \"running\" your code means that each cell of your code should execute from top to bottom with no errors. If someone clicks `Run All` then every cell should run. Leave enough time before you submit to restart your kernel and run your code from the beginning to ensure that it works, fix any issues, and repeat the operation until it runs smoothly top to bottom.\n",
        "\n",
        "***"
      ],
      "metadata": {
        "id": "dYPrgUN49O9Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0 Environment setup"
      ],
      "metadata": {
        "id": "zYFJCJwBvyfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount your drive here"
      ],
      "metadata": {
        "id": "qKRbdXqZInGc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "175c1e3d-49e7-4558-dd7c-dfd3bfcde479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Put all import statements in this cell.\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "rMo7zZraAwzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Data Acquisition\n",
        "\n",
        "he Kaggle page for the data is [here](https://www.kaggle.com/competitions/champs-scalar-coupling/overview).\n",
        "\n",
        "Be sure to agree to the competition rules to be able to download the data. See hints and possible troubleshooting help in https://github.com/fedhere/DSPS23_final\n",
        "- 1.1 Download the data programmatically in this notebook. There is a line of code at the bottom of [the Kaggle data page](https://www.kaggle.com/competitions/champs-scalar-coupling/data) which will do this.\n",
        "- 1.2 Make a folder in your Google Drive called `DSPS23_final` and put the data in there.\n",
        "  -   Do not expose your Kaggle API key by printing it anywhere in this notebook.\n",
        "  -   Recall that we did this for the Titanic dataset [here](https://github.com/fedhere/DSPS_FBianco/blob/main/CodeDemos/titanictree.ipynb).\n",
        "  -   The two files that you need are `train.csv` and `structures.csv`. Note that there is also a folder called `structures` which you do not need (and that unfortunately takes a long time to unpack, this may be useful https://unix.stackexchange.com/questions/14120/extract-only-a-specific-file-from-a-zipped-archive-to-a-given-directory)\n",
        "\n",
        "***\n",
        "\n",
        "<mark> If you are stuck on this task and would like to skip it, and forfeit the points from it </mark>, you may access the `train.csv` and `structures.csv` files from here https://fbb.space/classes/dsps2023/train.csv and https://fbb.space/classes/dsps2023/structures.csv (data folder).\n",
        "\n",
        "\n",
        "\n",
        "***"
      ],
      "metadata": {
        "id": "BxJTWVyLIY4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "ETwe7JEzMfW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "champs_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cy92br6WWvPe",
        "outputId": "8cc16f9f-995a-4c3a-bda4-65ab56b54c37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4659076, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "champs_structure.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrY-wSi-Wz-6",
        "outputId": "c13a2544-b28d-42a7-8351-79874d49d708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2358875, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the data size should be ^^^"
      ],
      "metadata": {
        "id": "vQkw-hB0XIMq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Data Cleaning, Preparation, and Fusion\n",
        "\n",
        "- 2.1 Read the files `train.csv` and `structures.csv` into Pandas dataframes.\n",
        "    - Note: Your target variable is `scalar_coupling_constant`.\n",
        "    - **In a text cell, answer this question**: What kind of machine learning task are we performing if we want to predict `scalar_coupling_constant`, given what type of variable it is.\n",
        "- 2.2 Check if there are any missing and/or duplicate values in this dataset.\n",
        "    - If there are missing values, you can fill them in or remove the corresponding row or column.\n",
        "    - If there are duplicate entries, you should remove them.\n",
        "- 2.3 Identify the columns containing molecule identifiers (i.e., not properties of the molecules that should be included in the model). NOTE: duplicate data may depend on the variables you decide to use so you may not have the same answer as others on this\n",
        "\n",
        "- 2.4 Each atom is associated with x-y-z values included in `structures.csv`. Merge the `structures` dataframe to the `train` dataframe. Note that there are 2 atoms involved so - see **HINT** in https://github.com/fedhere/DSPS23_final/edit/main/README.md:\n",
        "   \n",
        "- 2.5 At least one variable in the dataset is a multi-class categorical variable. One-hot encode this variable. One-hot encoding appeared a few times. See **HINT**\n",
        "\n",
        "***\n",
        "\n",
        "\n",
        "<mark> If you are stuck here do not waste too much time! YOu can skip this task, and forfeit the points from it </mark>, you may access the the file `data.csv` at https://fbb.space/classes/dsps2023/data.csv  folder. This file contains the data after completing all of the cleaning, merging and preparation steps in Task 2.\n",
        "\n",
        " It is also acceptable for you to use this code at the beginning of the exam, and then come back later to write your own code.\n",
        "\n",
        "\n",
        "***"
      ],
      "metadata": {
        "id": "rywxKndOLA1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "w556cwBlX3Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "champs_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRjbNCGSXUtf",
        "outputId": "9729cfa4-8564-44a5-850a-fdb81689dcfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4503143, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "given the choices we have made (and some of them may be different from yours!) this is the dataset we ended up with. But yours does not have to have this shape now. Your choice of dealing with NaNs or duplicated may lead to a different size dataset which is ok."
      ],
      "metadata": {
        "id": "PF67rGgoXnI8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION**: Given that we are predicting `scalar_coupling_constant`, what kind of machine learning task are we performing in this exam?\n",
        "\n",
        "YOUR ANSWER HERE"
      ],
      "metadata": {
        "id": "7zG1CH6DWpKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "KYBXlPWXVCBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Data Exploration\n",
        "\n",
        "Visualize the following aspects of the data in at least one figure:\n",
        "- The distribution of each feature in the data.\n",
        "- The correlation between features.\n",
        "\n",
        "Decide what to do in case you find peculiar distributions or strong correlations.\n",
        "\n",
        "**NB**: Some visualizations may take a lot of time to render. If it is taking too long, you may visualize a subset of the data."
      ],
      "metadata": {
        "id": "3lF92ScmQtqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "bxWzYVElnMry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 Model Choice and Preprocessing\n",
        "\n",
        "Now its time to choose your model.\n",
        "- 4.1 Justify your choice of model based on the nature of the data and the task to be performed.\n",
        "- 4.2 Prepare (i.e, scale, normalize or whiten) the data appropriately.\n",
        "- 4.3 Split the data into a training set and a testing set.\n",
        "    - If you wish, you may also split the data into three sets: training, validation, and testing.\n",
        "- 4.4 Run your model and tune the hyperparameters.\n",
        "\n",
        "There is an important hint reg this in https://github.com/fedhere/DSPS23_final/ README"
      ],
      "metadata": {
        "id": "P3anyRWKYO5c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96cPLlVVpxSk"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 Model Evaluation\n",
        "\n",
        "- 5.1 Test for convergence and overfitting.\n",
        "- 5.2 Report on the results and performance of your model.\n",
        "- 5.3 Visualize the predictions of your model against the true values of the target variable in at least one figure.\n",
        "\n",
        "Comments are important here! where is your model perfomeing well, where is it failing? How could you improve it?"
      ],
      "metadata": {
        "id": "7htjAEyZZXxD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCJ1Oq3RqV_u"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Extend Your Analysis Choose between one of the following two tasks\n",
        "\n",
        "**Option 1:** Repeat Tasks 4 and 5 with a different model.\n",
        "- If you used a **CART model** in Task 4...\n",
        "    - Make a plot of the feature importances of your model. Identify if there is a dominant feature. If there is, remove it and re-fit the data. If the dominant feature is a part of one-hot encoded features, then remove all of those features.\n",
        "- If you used a **neural network** in Task 4...\n",
        "    - Try changing the architecture. You could do this by changing the number of layers. Adding dropout layers to address overfitting. Changing the optimizer, loss, or activation functions. Be sure to justify your choices based on the data and the task at hand.\n",
        "- If you used **any other model** in Task 4...\n",
        "    - Try a CART model.\n",
        "\n",
        "**Option 2**, for whichever model you chose you can use additional variables or create additional features by manipulating and combining variables. For example, the x-y-z data can be turned into distances as seen [here](https://www.kaggle.com/code/artgor/molecular-properties-eda-and-models/notebook). This is called \"feature extraction\" and is an important part of data science."
      ],
      "metadata": {
        "id": "dbx6sJLREYXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "toIEyIq0bbCH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}